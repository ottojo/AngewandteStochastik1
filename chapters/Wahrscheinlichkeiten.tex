\chapter{Wahrscheinlichkeitsräume}
Ziel dieses Abschnittes ist die Mathematische Modellierung von Zufallsexperimenten

\section{Ergebnisraum Omega}
Der Ergebnisraum $\Omega$ ist die Menge aller möglichen Ergebnisse $\omega$ des
Zufallsexperimentes.

\paragraph{Beispiel} Eine Münze wird geworfen. $\Omega = \{K, Z\}$ ($K$opf, $Z$ahl), oder auch
$\Omega = \{0, 1\}$.

\paragraph{Beispiel} Ein Würfel wird geworfen. $\Omega = \{1,2,3,4,5,6\}$

\paragraph{Beispiel} Anzahl täglicher Bestellungen eines Artikels:
$\Omega = \{0,1,2,\dots\} = \mathbb{N}_0$

\paragraph{Beispiel} Temperatur am Schwörmontag an der Ulmer Adenauerbrücke:
$\Omega = [-50,50]$ oder $\Omega = \mathbb{R}$
\\

Beachte:
\begin{itemize}
    \item Bei der Wahl des Ergebnisraums gibt es kein \enquote{richtig} oder \enquote{falsch}.
          Das Ziel ist, einen einfachen aber adäquaten Raum zu wählen.
    \item Der Ergebnisraum kann unterschiedliche Kardinalität haben
          (in den Beispielen: endlich, abzählbar unendlich, überabzählbar unendlich).
\end{itemize}

\section{Ereignisse}
Motivation: Oft ist nicht das tatsächliche Ergebnis des Experiments interessant, sondern nur
ob das Ergebnis in eine vorgegebene Menge von Ergebnissen $A$ fällt.

\paragraph{Beispiel: Würfeln} Augenzahl ist gerade: $A = \{2,4,6\}$

\paragraph{Beispiel: Anzahl täglicher Bestellungen} Vorrat von 100 Artikeln wird nicht
überschritten: $A = \{0,1,2,\dots,100\}$.

\paragraph{Beispiel: Temperatur} Temperatur beträgt über $25\degree$:
$A = [25,50]$ (falls $\Omega = [-50,50])$ oder $A= [25, \infty)$ (falls $\Omega = \mathbb{R}$)
\\

Diese Teilmengen$A$ von $\Omega$, denen Wahrscheinlichkeiten zugeordnet werden sollen,
heißen \emph{Ereignisse}.
Man sagt \enquote{Das Ergebnis A tritt ein}, falls das Ergebbnis $\omega$ des Zufallexperimentes
in dieser Menge $A$ liegt (d.h. $\omega \in A$).
Mittels Mengenoperationen können Ereignisse zu neuen Ereignissen verknüpft werden.

\begin{itemize}
    \item $A \cup B$: Ereignis $A$ oder Ereignis $B$ tritt ein.

    \item $A \cap B$: Ereignis $A$ und Ereignis $B$ treten ein.

    \item $A\setminus B$: Ereignis $A$, nicht aber Ereignis $B$ tritt ein.

    \item $A^\complement = \Omega\setminus A$: Ereignis $A$ tritt nicht ein.

    \item $\bigcup\limits_{i=1}^\infty A_i$: Mindestens eines der Ereignisse
          $A_1, A_2, \dots$ tritt ein.

    \item $\bigcap\limits_{i=1}^\infty A_i$: Alle Ereignisse $A_1, A_2, \dots$
          treten ein.
\end{itemize}

\paragraph{Beispiel} Münze wird zwei Mal geworfen.\\
$\Omega = \{KK, KZ, ZK, ZZ\}$\\
Sei $A_1$ das Ereignis \enquote{Im ersten Wurf fällt Kopf} und\\
sei $A_2$ das Ereignis \enquote{Im zweiten Wurf fällt Kopf}. Dann gilt\\
$A_1 = \{KK, KZ\}$, $A_2 = \{KK, ZK\}$.\\
Die Menge $A_1 \cup A_2 = \{KK, KZ, ZK\}$ ist das Ereignis \enquote{Es fällt mindestens ein Mal
    Kopf}.\\
Die Menge $A_1 \cap A_2 = \{KK\}$ ist das Ereignis \enquote{Es fällt zwei Mal Kopf}.\\


\section{Sigma-Algebra}
Welchen Teilmengen $A$ von $\Omega$ sollen Wahrscheinlichkeiten $P(A)$ zugeordnet werden?
Ideal wäre: man definiert $P(A)$ für alle $A \subset \Omega$, das heißt für alle
$A \in \mathbb{P}(\Omega) := \{B:B\subset\Omega\}$, die Potenzmenge von $\Omega$.
Das geht, falls $\Omega$ endlich oder anzählbar ist.
Es ist aber im Allgemeinen nicht möglich
(z.B. falls $\Omega = \mathbb{R}$).
Deswegen beschränkt man sich auf ein Teilsystem $\Sigma \subseteq \mathbb{P}(\Omega)$ von
Ereignissen.
\paragraph{Forderungen an $\Sigma$:}
Mengenoperationen mit Ereignissen liefern wieder Ereignisse.

\begin{definition}
    Sei $\Omega \neq \emptyset$ eine beliebige Menge.
    Eine Menge $\Sigma \subseteq \mathbb{P}(\Omega)$ heißt eine $\sigma$-Algebra, falls
    \begin{enumerate}
        \item $\Omega \in \Sigma$
        \item Falls $A \in \Sigma$, dann gilt $A^\complement \in \Sigma$
        \item Falls $A_1, A_2, \dots \in \Sigma$, dann gilt:
              $\bigcup\limits_{i=1}^\infty A_i \in \Sigma$
    \end{enumerate}
\end{definition}

Die Elemente der $\sigma$-Algebra heißen \emph{Ereignis}.
Es folgt, dass $\emptyset$ ein Element jeder $\sigma$-Algebra ist. Dieses Ereignis heißt
\emph{unmögliches Ereignis} und tritt nie ein.
Es folgt, dass \emph{endliche Vereinigungen von Ereignissen} auch Ereignisse sind.

\paragraph{Beispiel: Münzwurf}
$\Omega = \{K, Z\}$. Die Mengen\\
$\Sigma_1=\{\Omega, \emptyset\}$ und\\
$\Sigma_2=\{\Omega, \emptyset, \{K\}, \{Z\}\} = \mathbb{P}(\Omega)$ sind $\sigma$-Algebren.\\
Die $\sigma$-Algebra $\Sigma_1$ heißt die \emph{triviale $\sigma$-Algebra}.\\
Beachte: $K \notin \Sigma_2$, aber $\{K\} \in \Sigma_2$, Ergebnisse sind \emph{keine} Ereignisse!

\paragraph{Beispiel:} $\Omega = \{1,2,3\}$\\
Dann sind die Mengen\\
$\Sigma_1 = \{\Omega, \emptyset\}$,\\
$\Sigma_2 = \{\Omega, \emptyset, \{1\}, \{2,3\}\}$,\\
$\Sigma_3 = \{\Omega, \emptyset, \{2\}, \{1,3\}\}$,\\
$\Sigma_4 = \{\Omega, \emptyset, \{3\}, \{1,2\}\}$,\\
$\Sigma_5 = \{\Omega, \emptyset, \{1\}, \{2\}, \{2,3\}, \{1,3\}, \{1,2\}, \{3\} \} = \mathbb{P}(\Omega)$
$\sigma$-Algebren

\begin{theorem}
    Für jede $\sigma$-Algebra $\Sigma$ gilt
    \begin{enumerate}
        \item $\emptyset \in \Sigma$
        \item falls $A, B \in \Sigma$ dann gilt: $A \cup B, A \cap B, A \setminus B \in \Sigma$
        \item falls $A_1,A_2,\dots \in \Sigma$, dann gilt $\bigcap\limits_{i=1}^\infty A_i \in \Sigma$
    \end{enumerate}
\end{theorem}

\section{Wahrscheinlichkeiten}

Wir definieren $P(A)$ für alle $A \in \Sigma$.
\begin{definition}[Disjunkte Mengen]
    Mengen $A, B$ heißen disjunkt, falls $A\cap B = \emptyset$\\
    Mengen $A_1, A_2, \dots$ heißen paarweise disjunkt (p.d.) falls für alle $i \neq j$ gilt
    $A_i \cap A_j = \emptyset$
\end{definition}

Idee: P soll folgende Eigenschaften haben:
\begin{enumerate}
    \item Für alle $A\in \Sigma$ gilt: $0 \leq P(A)\leq 1$
    \item $P(\Omega) = 1$ und $P(\emptyset) = 0$
    \item $P(A^\complement) = 1-P(A)$ für alle $A\in \Sigma$
    \item falls $A,B\in\Sigma$ disjunkt sind, so gilt
          $P(A\cup B) = P(A) + P(B)$.
    \item falls $A_1, A_2,\dots \in \Sigma$ p.d., so gilt
          $P(\bigcup\limits_{i=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)$
\end{enumerate}

Das motiviert folgende Definition

\begin{definition}[Wahrscheinlichkeitsmaß]
    Sei $\Omega \neq \emptyset$ und \tS\ eine \ts-Algebra auf \tO.
    Eine Abbildung $P: \Sigma \to [0,1]$ heißt Wahrscheinlichkeitsmaß (W-Maß) auf \tS\ falls
    \begin{enumerate}
        \item $P(\Omega) = 1$
        \item Sind $A_1, A_2,\dots \in \Sigma$ paarweise disjunkt, dann gilt
              $P\left(\bigcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty P(A_i)$
              (\ts-Additivität)
    \end{enumerate}
\end{definition}
\noindent
Das Tripel $\left( \Omega, \Sigma, P\right)$ heißt \emph{Wahrscheinlichkeitsraum} (W-Raum).

\section{Beispiele zum Wahrscheinlichkeitsraum}
\subsection{Münzwurf}
Modellierung durch den Wahrscheinlichkeitsraum $(\Omega, \Sigma, P)$ mit\\
$\Omega = \{K,Z\},$\\
$\Sigma = \mathbb{P}(\Omega) = \{ \Omega, \emptyset, \{K\}, \{Z\}\}$\\
$P: \Sigma \to [0,1]$ mit\\
$P(\Omega) = 1, P(\emptyset) = 0, P(\{K\}) = 0.5, P(\{Z\}) = 0.5$

\subsection{Würfeln}
Modellierung durch den Wahrscheinlichkeitsraum $(\Omega, \Sigma, P)$ mit\\
$\Omega = \{1,2,\dots,6\}$\\
$\Sigma =\mathbb{P}(\Omega)$\\
$P: \Sigma \to [0,1]$ mit\\
$P(\Omega) = 1, P(\emptyset) = 0$,\\
$P(\{1\})=\frac{1}{6}, P(\{2\})=\frac{1}{6}, \dots$\\
$P(\{1, 2\})=\frac{1}{3}, P(\{1,2,3\})=\frac{1}{2}$\\
Also kann man kürzer schreiben $P(A) = \frac{|A|}{|\Omega|}$, mit $|A|$ der Anzahl der Elemente in $A$
(Kardinalität von $A$).

\subsection{Geschlecht von Neugeborenen}
Modellierung durch den Wahrscheinlichkeitsraum $(\Omega, \Sigma, P)$ mit\\
$\Omega = \{W,M\}$\\
$\Sigma = \mathbb{P}(\Omega\}$\\
$P: \Sigma \to [0,1]$ mit\\
$P(\Omega) = 1, P(\emptyset)=0$\\
$P(\{W\}) = p, P(\{M\}) = 1-p$, wobei $p \in [0,1]$.\\
Wahl von $p$: länderspezifisch auf Basis relativer Häufigkeiten, z.B. für Deutschland $p=0.4863$ (1970-1999).

\section{Eigenschaften von W-Maßen}
\begin{theorem}[Eigenschaften von W-Maßen]
    Sei $(\Omega, \Sigma, P)$ ein W-Raum, und seien $A, B, A_1, A_2, \dots \in \Sigma$.
    \begin{enumerate}
        \item Ist $A \subseteq B$, so gilt $P(B) = P(A) + P(B\setminus A)$ und
              $P(A) \leq P(B)$ (Monotonie)
        \item $P(A \cup B) = P(A) + P(B) - P(A\cap B)$
        \item $P\left(\cup_{i=1}^\infty A_i\right) \leq \sum_{i=1}^\infty P(A_i)$ (\ts-Subadditivität)
    \end{enumerate}
\end{theorem}


\section{Endliche Wahrscheinlichkeitsräume}
In diesem Abschnitt: \tO\ ist endlich, d.h. $\Omega = \{\omega_1, \omega_2, \dots, \omega_n\}$
für ein $n \in \mathbb{N}$.
In diesem Fall kann man $\Sigma = \mathbb{P}(\Omega)$ wählen.
Ferner ist ein W-Maß $P$ bereits durch die Werte $p_i = P(\{\omega_i\}), i=1,\dots,n$
von Elementarereignissen $\{\omega_i\}$ eindeutig bestimmt.

\begin{definition}[Endlicher W-Raum]
    Ein W-Raum $(\Omega, \Sigma,  P)$ heißt \emph{endlicher W-Raum}, falls \tO\ endlich ist und
    $\Sigma = \mathbb{P}(\Omega)$ gilt.
\end{definition}

Beachte: Sei $(\Omega, \Sigma, P)$ ein endlicher W-Raum. Im Allgemeinen ist es nicht der Fall, dass alle
Elementarereignisse gleichwahrscheinlich sind.

\paragraph{Laplace W-Räume} Ein besonders einfacher Fall liegt dann vor, wenn alle Elementarereignisse
$\{\omega_i\}$ gleichwahrscheinlich sind.

\begin{definition}[Laplace-W-Raum]
    Ein endlicher W-Raum $(\Omega, \Sigma, P)$ und $p_i = P(\{\omega_i\}) = \frac{1}{|\Omega|} = \frac{1}{n}$
    für alle $i=1,\dots,n$ heißt \emph{Laplace-W-Raum}.
    Das W-Maß $P$ heißt \emph{diskrete Gleichverteilung}.
    Man schreibt $P=U(\Omega)$ (\textit{uniform}).
    Ein Zufallsexperiment, welches durch einen Laplace-Raum bechrieben ist, nennt man ein
    Laplace-Experiment.
\end{definition}

Sei \wraum\ ein Laplace W-Raum. Es folgt:
\begin{equation*}
    P(A) = \sum_{\w_i \in A} P(\{\w_i\}) = \sum_{\w_i \in A} \frac{1}{|\tO|} = \frac{|A|}{|\tO|}
\end{equation*}
Die Bestimmung der Kardinalitäten von \tO\ und $A$ kann nichttrivial sein.

\begin{theorem}
    Seien $A_1, \dots ,A_n$ endliche Mengen und $A= \{ (a_1, \dots , a_n): a_1 \in A_1, \dots , a_n \in A_n \} = A_1 \times \dots \times A_n$.
    Dann gilt $|A| = |A_1| \cdot |A_2| \cdots |A_n|$
\end{theorem}

\subsection{Urnenmodelle}
\begin{itemize}
    \item Urne mit $n$ Kugeln, welche nummeriert sind mit $1, \dots , n$.
    \item Zufälliges Ziehen von $k$ Kugeln
\end{itemize}
Das Ergebnis ist ein Vektor $(\w_1,\dots , \w_k)$ wobei ein Element jeweils die
Nummer einer Kugel ist.

\subsubsection{Verschiedene Arten von Ziehungen}
\begin{enumerate}
    \item Mit Zurücklegen (z.B Ergebnis $(1,1,2,2)$ möglich) \\
          Ohne Zurücklegen (z.B. Ergebnis $(1,1,2,2)$ nicht möglich)
    \item Mit Beachten der Reihenfolge\\
          Ohne Beachten der Reihenfolge
\end{enumerate}
$\implies$ Insgesamt 4 mögliche Fälle.

\subsubsection{Fall 1: Mit Zurücklegen und mit Beachtung der Reihenfolge}
Die Menge aller Ergebnisse ist
\begin{align*}
    \tO_1 & = \{ (\w_1, \dots ,\w_k): \w_1, \dots ,\w_k \in \{1,\dots ,n\} \} \\
          & =\{ 1,\dots ,n \}^k
\end{align*}
Für die Kardinalität der Menge gilt
\begin{equation*}
    |\tO_1| = n^k
\end{equation*}

\subsubsection{Fall 2: Ohne Zurücklegen, mit Beachtung der Reihenfolge}
$\implies k \leq n$.\\
Menge aller Ergebnisse:
\begin{equation*}
    \tO_2 = \{ (\w_1, \dots ,\w_k): \w_1, \dots ,\w_k \in \{ 1, \dots ,n \} \text{ und } \w_i \neq \w_j \text{ für } i \neq j \}
\end{equation*}
Es gilt:
\begin{equation*}
    |\tO_2| = n \cdot (n-1) \cdot (n-2) \cdots (n-k+1) = \frac{n!}{(n-k)!}
\end{equation*}
Insbesondere gilt für $n=k$: $|\tO_2| = n!$.

\subsubsection[Urnenmodell, Fall 3]{Fall 3: Ohne Zurücklegen, ohne Beachtung der Reihenfolge}
\label{sec:urne3}
$\implies k \leq n$.\\
Vorgehen: Erst Beachten der Reihenfolge, dann sortieren der Vektoren in aufsteigender Reihenfolge.
\begin{equation*}
    \tO_3 = \{ (\w_1, \dots ,\w_k): 1 \leq \w_1 < \w_2 < \dots < \w_k \leq k \}
\end{equation*}
\begin{equation*}
    |\tO_3| = \frac{|\tO_2|}{k!} = \frac{n!}{(n-k)! \cdot k!} = \binom{n}{k}
\end{equation*}

\subsubsection{Fall 4: Mit Zurücklegen, ohne Beachtung der Reihenfolge}
Analog zu Fall 3:
\begin{equation*}
    \tO_4 = \{ (\w_1, \dots ,\w_k): 1 \leq \w_1 \leq \w_2 \leq \dots \leq \w_k \leq k \}
\end{equation*}
Die Kardinalität ist (ohne Beweis):
\begin{equation*}
    |\tO_4| = \binom{n+k-1}{k}
\end{equation*}

\subsection{Weitere W-Maße in endlichen W-Räumen}
\subsubsection{Hypergeometrische Verteilung}
Darstellung im Urnenmodell: Die Urne enthält $n$ Kugeln, davon sind $B$ blau, und $n-B$ weiß.
Dabei ist $B \in \{0,\dots ,n\}$. Es werden $k$ Kugeln gezogen, ohne Zurücklegen und ohne beachten
der Reihenfolge.

Es soll nun für $b \in  \{0,\dots ,k\}$ die Wahrscheinlichkeit berechnet werden für das Ereignis
$A_b$ = "genau $b$ der gezogenen Kugeln sind blau".

Dazu wird das Experiment mit einen Laplace Raum modelliert, mit
\begin{equation*}
    \tO = \{ (\w_1, \dots ,\w_k): 1 \leq \w_1 < \w_2 < \dots < \w_k \leq n \}
\end{equation*}
(analog zu \nameref{sec:urne3}). \w\ ist dabei die Nummer einer Kugel.
Da es sich um einen Laplace Raum handelt, gilt
\begin{equation*}
    P(A_b) = \frac{|A_b|}{|\tO|}
\end{equation*},
und aus dem Urnenmodell ergibt sich
\begin{equation*}
    |\tO| = \binom{n}{k}
\end{equation*}.
Nun muss die Kardinalität $|A_b|$ bestimmt werden.
Für die Fälle "mehr blaue Kugeln als in der Urne vorhanden" und
"mehr weiße Kugeln als in der Urne vorhanden", kann bereits festgestellt werden:
\begin{equation*}
    |A_b| = \begin{cases}
        0 & \text{falls } b>B                      \\
        0 & \text{falls } b-k>n-B (\iff b<k-(n-B))
    \end{cases}
\end{equation*}

In allen anderen Fällen gilt
\begin{equation*}
    |A_b| = \underbrace{\binom{B}{b}}_\text{
        \hidewidth
        Anzahl an Möglichkeiten für $b$ blaue Kugeln
        \hidewidth} \cdot
    \overbrace{\binom{n-B}{k-b}}^\text{
        \hidewidth
        Anzahl an Möglichkeiten für $k-b$ weiße Kugeln
        \hidewidth }
\end{equation*}
Damit folgt:
\begin{equation*}
    P(A_b)= \begin{cases}
        0                                                  & \text{falls } b>B \text{ oder } b<k-(n-B) \\
        \frac{\binom{B}{b} \binom{n-B}{k-b}}{\binom{n}{k}} & \text{sonst}
    \end{cases}
\end{equation*}

Das gleiche Experiment kann auch anders modelliert werden:
\begin{equation*}
    \tO = \{ 0, \dots ,k \}, \Sigma = \mathbb{P}(\tO)
\end{equation*}
\begin{equation*}
    P(\{b\}) = \begin{cases}
        0                                                  & \text{falls } b>B \text{ oder } b<k-(n-B) \\
        \frac{\binom{B}{b} \binom{n-B}{k-b}}{\binom{n}{k}} & \text{sonst}
    \end{cases}
\end{equation*}
\begin{equation*}
    P(A) = \sum_{b \in A} P(\{b\})
\end{equation*}
Dieses W-Maß heißt \emph{Hypergeometrische Verteilung} mit Parametern $n, B, k$.
Man schreibt $P=H(n,B,k)$.

\subsubsection{Bernoulli Verteilung}
\label{sec:bernoulli}
Hier sind die einzig möglichen Ergebnisse "Erfolg" und "Misserfolg":
$\tO = \{ 0,1 \}$, $\tS = P(\tO)$.
Die Erfolgswahrscheinlichkeit ist gegeben durch $p \in [0,1]$:
\begin{align*}
    P(\{1\})     & = p   \\
    P(\{0\})     & = 1-p \\
    P(\emptyset) & = 0   \\
    P(\tO)       & = 1
\end{align*}
Dieses Wahrscheinlichkeitsmaß heißt Bernoulli Verteilung mit Parameter $p$.
Man schreibt $P=B(1,p)$.

\subsubsection{Binomial Verteilung}
Hier wird das Experiment der \nameref{sec:bernoulli} $n$-malig wiederholt.
Modellierung durch den W-Raum \wraum\ mit:
\begin{align*}
    \tO       & = \left\{ (\w_1, \dots , \w_n): \w_1, \dots , \w_n \in \{0,1\} \right\} = \{0,1\}^n \\
    \tS       & = P(\tO)                                                                            \\
    P(\{\w\}) & = P(\{(\w_1, \dots , \w_n)\}) = p^k \cdot (1-p)^{n-k}
\end{align*}
Wobei $k=\sum_{i=1}^n \w_i$ die Anzahl der Erfolge ist.

\begin{equation*}
    P(A) = \sum_{\w \in A} P(\{\w\}), \; A \in \tS
\end{equation*}
Betrachtet wird das Ereignis $A_k =$ "genau $k$ Erfolge" mit $k \in \{0, \dots , n\}$.
Es gilt:
\begin{align*}
    P(A_k) & = \sum_{\w \in A_k} P(\{ \w \})            \\
           & = \sum_{\w \in A_k} p^k (1-p)^{n-k}        \\
           & = \binom{n}{k} \cdot p^k \cdot (1-p)^{n-k}
\end{align*}
Modellierung mit anderem W-Raum:
\begin{align*}
    \tO      & = \{0,1,\dots ,n\}                         \\
    \tS      & = P(\tO)                                   \\
    P(\{k\}) & = \binom{n}{k} \cdot p^k \cdot (1-p)^{n-k} \\
    P(A)     & = \sum_{k \in A} P(\{k\}), \; A \in \tS
\end{align*}
Hier ist das Ereignis nicht mehr der Vektor mit Resultaten,
sondern direkt die Anzahl an Erfolgen.
Dieses W-Maß heißt Binomialverteilung mit Parametern $n$ und $p$.
Man schreibt $P = B(n,p)$.

\subsection{Diskrete Wahrscheinlichkeitsräume}
Bisher war \tO\ endlich. In diesem Abschnitt soll \tO\ abzählbar unendlich sein, d.h.
$\tO = \{ \w_1, \w_2, \dots\}$, $\w_i \neq \w_j$ für $i \neq j$.

\subsubsection{Poisson Verteilung}
$\tO = \mathbb{N}_0$, $\tS = P(\tO)$
\begin{align*}
    P(\{k\}) & = \frac{\lambda^k}{k!} \cdot e^{-\lambda}, \; k \in \mathbb{N}_0, \; \lambda > 0 \\
    P(A)     & = \sum_{k \in A} P(\{k\}), \; A \in \tS
\end{align*}
Mit der Reihenentwicklung der Exponentialfunktion lässt sich zeigen dass $P(\tO) = 1$.
$P$ heißt Poissonverteilung mit Parameter $\lambda > 0$: $P = P(\lambda)$